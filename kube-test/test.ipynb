{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../01_xlsx/0104.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>provincia</th>\n",
       "      <th>ciudad</th>\n",
       "      <th>dni</th>\n",
       "      <th>candidato</th>\n",
       "      <th>esvalido</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Nieva</td>\n",
       "      <td>58228644</td>\n",
       "      <td>Cynthia Yancy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Nieva</td>\n",
       "      <td>72133897</td>\n",
       "      <td>Raymond Cannon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Nieva</td>\n",
       "      <td>66194409</td>\n",
       "      <td>Stephen Orsborn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Nieva</td>\n",
       "      <td>46647505</td>\n",
       "      <td>Stephen Orsborn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Nieva</td>\n",
       "      <td>26359987</td>\n",
       "      <td>Raymond Cannon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Río Santiago</td>\n",
       "      <td>87058821</td>\n",
       "      <td>Cynthia Yancy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Río Santiago</td>\n",
       "      <td>71136516</td>\n",
       "      <td>Cynthia Yancy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Río Santiago</td>\n",
       "      <td>52048932</td>\n",
       "      <td>Raymond Cannon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Río Santiago</td>\n",
       "      <td>81649067</td>\n",
       "      <td>Raymond Cannon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>Condorcanqui</td>\n",
       "      <td>Río Santiago</td>\n",
       "      <td>30214331</td>\n",
       "      <td>Raymond Cannon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2228 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        region     provincia        ciudad       dni        candidato  \\\n",
       "0     Amazonas  Condorcanqui         Nieva  58228644    Cynthia Yancy   \n",
       "1     Amazonas  Condorcanqui         Nieva  72133897   Raymond Cannon   \n",
       "2     Amazonas  Condorcanqui         Nieva  66194409  Stephen Orsborn   \n",
       "3     Amazonas  Condorcanqui         Nieva  46647505  Stephen Orsborn   \n",
       "4     Amazonas  Condorcanqui         Nieva  26359987   Raymond Cannon   \n",
       "...        ...           ...           ...       ...              ...   \n",
       "2223  Amazonas  Condorcanqui  Río Santiago  87058821    Cynthia Yancy   \n",
       "2224  Amazonas  Condorcanqui  Río Santiago  71136516    Cynthia Yancy   \n",
       "2225  Amazonas  Condorcanqui  Río Santiago  52048932   Raymond Cannon   \n",
       "2226  Amazonas  Condorcanqui  Río Santiago  81649067   Raymond Cannon   \n",
       "2227  Amazonas  Condorcanqui  Río Santiago  30214331   Raymond Cannon   \n",
       "\n",
       "      esvalido  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  \n",
       "...        ...  \n",
       "2223         1  \n",
       "2224         1  \n",
       "2225         0  \n",
       "2226         1  \n",
       "2227         1  \n",
       "\n",
       "[2228 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kafka-python in /home/home-server/.local/lib/python3.10/site-packages (2.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kafka\n",
    "\n",
    "\n",
    "consumer = kafka.KafkaConsumer(security_protocol=\"PLAINTEXT\",group_id='test', bootstrap_servers=['localhost:9094'])\n",
    "topics = consumer.topics()\n",
    "\n",
    "if not topics: \n",
    "    raise RuntimeError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     producer\u001b[39m.\u001b[39msend(\u001b[39m'\u001b[39m\u001b[39mnumtest\u001b[39m\u001b[39m'\u001b[39m, value\u001b[39m=\u001b[39mdata)\n\u001b[1;32m     15\u001b[0m     i \u001b[39m=\u001b[39m i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> 17\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m \u001b[39m# >>> from kafka import KafkaProducer\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# >>> producer = KafkaProducer(bootstrap_servers='localhost:1234')\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# >>> for _ in range(100):\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# ...     producer.send('foobar', b'some_message_bytes')\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:9094'],\n",
    "                         value_serializer=lambda x: \n",
    "                         dumps(x).encode('utf-8'))\n",
    "\n",
    "i = 1000\n",
    "while True:\n",
    "    # producer.send('pageview2', b'aaa')\n",
    "    # producer.send('numtest', b'aaa')\n",
    "    data = {'number' : i}\n",
    "    producer.send('numtest', value=data)\n",
    "    i = i+1\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# >>> from kafka import KafkaProducer\n",
    "# >>> producer = KafkaProducer(bootstrap_servers='localhost:1234')\n",
    "# >>> for _ in range(100):\n",
    "# ...     producer.send('foobar', b'some_message_bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     consumer \u001b[39m=\u001b[39m KafkaConsumer(security_protocol\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPLAINTEXT\u001b[39m\u001b[39m\"\u001b[39m,bootstrap_servers\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mKAFKA_IP\u001b[39m}\u001b[39;00m\u001b[39m:9094\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                         auto_offset_reset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mearliest\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                         group_id\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpageview-group1\u001b[39m\u001b[39m'\u001b[39m,)\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mfor\u001b[39;00m message \u001b[39min\u001b[39;00m consumer:\n\u001b[1;32m      9\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39m            topic     => \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39mtopic\u001b[39m}\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m            partition => \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39mpartition\u001b[39m}\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m            offset    => \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39moffset\u001b[39m}\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m            key=\u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39mkey\u001b[39m}\u001b[39;00m\u001b[39m value=\u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:1193\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_v1()\n\u001b[1;32m   1192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext_v2()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:1201\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator)\n\u001b[1;32m   1202\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:1116\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_message_generator_v2\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1115\u001b[0m     timeout_ms \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consumer_timeout \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mtime())\n\u001b[0;32m-> 1116\u001b[0m     record_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoll(timeout_ms\u001b[39m=\u001b[39;49mtimeout_ms, update_offsets\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1117\u001b[0m     \u001b[39mfor\u001b[39;00m tp, records \u001b[39min\u001b[39;00m six\u001b[39m.\u001b[39miteritems(record_map):\n\u001b[1;32m   1118\u001b[0m         \u001b[39m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m         \u001b[39m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m         \u001b[39m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m         \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m records:\n\u001b[1;32m   1122\u001b[0m             \u001b[39m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m             \u001b[39m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m             \u001b[39m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m             \u001b[39m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    653\u001b[0m remaining \u001b[39m=\u001b[39m timeout_ms\n\u001b[1;32m    654\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     records \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll_once(remaining, max_records, update_offsets\u001b[39m=\u001b[39;49mupdate_offsets)\n\u001b[1;32m    656\u001b[0m     \u001b[39mif\u001b[39;00m records:\n\u001b[1;32m    657\u001b[0m         \u001b[39mreturn\u001b[39;00m records\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:702\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mpoll(timeout_ms\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    701\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(timeout_ms, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_coordinator\u001b[39m.\u001b[39mtime_to_next_poll() \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[0;32m--> 702\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mpoll(timeout_ms\u001b[39m=\u001b[39;49mtimeout_ms)\n\u001b[1;32m    703\u001b[0m \u001b[39m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[39m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_coordinator\u001b[39m.\u001b[39mneed_rejoin():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/client_async.py:602\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[0;34m(self, timeout_ms, future)\u001b[0m\n\u001b[1;32m    599\u001b[0m             timeout \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(timeout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mretry_backoff_ms\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    600\u001b[0m         timeout \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, timeout)  \u001b[39m# avoid negative timeouts\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout \u001b[39m/\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m    604\u001b[0m \u001b[39m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[39m# if handlers need to acquire locks\u001b[39;00m\n\u001b[1;32m    606\u001b[0m responses\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/client_async.py:634\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_register_send_sockets()\n\u001b[1;32m    633\u001b[0m start_select \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 634\u001b[0m ready \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    635\u001b[0m end_select \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sensors:\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:469\u001b[0m, in \u001b[0;36mEpollSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    467\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    468\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 469\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout, max_ev)\n\u001b[1;32m    470\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "KAFKA_IP = \"localhost\"\n",
    "l = []\n",
    "try:\n",
    "    consumer = KafkaConsumer(security_protocol=\"PLAINTEXT\",bootstrap_servers=f'{KAFKA_IP}:9094',\n",
    "                        auto_offset_reset='earliest',\n",
    "                        group_id='pageview-group1',)\n",
    "    for message in consumer:\n",
    "        print(f\"\"\"\n",
    "            topic     => {message.topic}\n",
    "            partition => {message.partition}\n",
    "            offset    => {message.offset}\n",
    "            key={message.key} value={message.value}\n",
    "        \"\"\")\n",
    "except Exception as e:\n",
    "    print (str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkafka\u001b[39;00m \u001b[39mimport\u001b[39;00m KafkaConsumer\n\u001b[1;32m      3\u001b[0m consumer \u001b[39m=\u001b[39m KafkaConsumer(\u001b[39m'\u001b[39m\u001b[39mpageview2\u001b[39m\u001b[39m'\u001b[39m,security_protocol\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPLAINTEXT\u001b[39m\u001b[39m\"\u001b[39m,bootstrap_servers\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocalhost:9092\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                          auto_offset_reset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mearliest\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                          group_id\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpageview-group1\u001b[39m\u001b[39m'\u001b[39m,)\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfor\u001b[39;00m message \u001b[39min\u001b[39;00m consumer:\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m        topic     => \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39mtopic\u001b[39m}\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m        partition => \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39mpartition\u001b[39m}\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m        offset    => \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39moffset\u001b[39m}\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m        key=\u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39mkey\u001b[39m}\u001b[39;00m\u001b[39m value=\u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:1193\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_v1()\n\u001b[1;32m   1192\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1193\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext_v2()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:1201\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_generator_v2()\n\u001b[1;32m   1200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator)\n\u001b[1;32m   1202\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:1116\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_message_generator_v2\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1115\u001b[0m     timeout_ms \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consumer_timeout \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mtime())\n\u001b[0;32m-> 1116\u001b[0m     record_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoll(timeout_ms\u001b[39m=\u001b[39;49mtimeout_ms, update_offsets\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1117\u001b[0m     \u001b[39mfor\u001b[39;00m tp, records \u001b[39min\u001b[39;00m six\u001b[39m.\u001b[39miteritems(record_map):\n\u001b[1;32m   1118\u001b[0m         \u001b[39m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m         \u001b[39m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m         \u001b[39m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m         \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m records:\n\u001b[1;32m   1122\u001b[0m             \u001b[39m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m             \u001b[39m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m             \u001b[39m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m             \u001b[39m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    653\u001b[0m remaining \u001b[39m=\u001b[39m timeout_ms\n\u001b[1;32m    654\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     records \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll_once(remaining, max_records, update_offsets\u001b[39m=\u001b[39;49mupdate_offsets)\n\u001b[1;32m    656\u001b[0m     \u001b[39mif\u001b[39;00m records:\n\u001b[1;32m    657\u001b[0m         \u001b[39mreturn\u001b[39;00m records\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/consumer/group.py:675\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[0;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll_once\u001b[39m(\u001b[39mself\u001b[39m, timeout_ms, max_records, update_offsets\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    666\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Do one round of polling. In addition to checking for new data, this does\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m    any needed heart-beating, auto-commits, and offset updates.\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39m        dict: Map of topic to list of records (may be empty).\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coordinator\u001b[39m.\u001b[39;49mpoll()\n\u001b[1;32m    677\u001b[0m     \u001b[39m# Fetch positions if we have partitions we're subscribed to that we\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39m# don't know the offset for\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_subscription\u001b[39m.\u001b[39mhas_all_fetch_positions():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/coordinator/consumer.py:289\u001b[0m, in \u001b[0;36mConsumerCoordinator.poll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m             metadata_update \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mcluster\u001b[39m.\u001b[39mrequest_update()\n\u001b[1;32m    287\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mpoll(future\u001b[39m=\u001b[39mmetadata_update)\n\u001b[0;32m--> 289\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mensure_active_group()\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_heartbeat()\n\u001b[1;32m    293\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_auto_commit_offsets_async()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/coordinator/base.py:353\u001b[0m, in \u001b[0;36mBaseCoordinator.ensure_active_group\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_heartbeat_thread()\n\u001b[1;32m    352\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneed_rejoin() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rejoin_incomplete():\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mensure_coordinator_ready()\n\u001b[1;32m    355\u001b[0m     \u001b[39m# call on_join_prepare if needed. We set a flag\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[39m# to make sure that we do not call it a second\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[39m# time if the client is woken up before a pending\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[39m# changes the matched subscription set) can occur\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[39m# while another rebalance is still in progress.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrejoining:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kafka/coordinator/base.py:267\u001b[0m, in \u001b[0;36mBaseCoordinator.ensure_coordinator_ready\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mpoll(future\u001b[39m=\u001b[39mmetadata_update)\n\u001b[1;32m    266\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 267\u001b[0m         time\u001b[39m.\u001b[39;49msleep(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mretry_backoff_ms\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m/\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m    268\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[39mraise\u001b[39;00m future\u001b[39m.\u001b[39mexception\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer('pageview2',security_protocol=\"PLAINTEXT\",bootstrap_servers='localhost:9092',\n",
    "                         auto_offset_reset='earliest',\n",
    "                         group_id='pageview-group1',)\n",
    "for message in consumer:\n",
    "    print(f\"\"\"\n",
    "        topic     => {message.topic}\n",
    "        partition => {message.partition}\n",
    "        offset    => {message.offset}\n",
    "        key={message.key} value={message.value}\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
